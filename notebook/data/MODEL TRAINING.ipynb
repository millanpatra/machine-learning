{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install required packages if missing (run this cell once)\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def _ensure_pkg(*names):\n",
        "    for name in names:\n",
        "        try:\n",
        "            __import__(name)\n",
        "        except ImportError:\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", name, \"-q\"])\n",
        "_ensure_pkg(\"numpy\", \"pandas\", \"matplotlib\", \"seaborn\", \"scikit-learn\", \"xgboost\", \"catboost\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "0cdd3a11"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Modelling\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from catboost import CatBoostRegressor\n",
        "from xgboost import XGBRegressor"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'numpy'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m \n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
          ]
        }
      ],
      "id": "6d19c16f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load the dataset (find stud.csv in notebook folder or workspace)\n",
        "import os\n",
        "_candidates = [\n",
        "    'stud.csv',\n",
        "    os.path.join(os.getcwd(), 'data', 'stud.csv'),\n",
        "    os.path.join(os.getcwd(), 'notebook', 'data', 'stud.csv'),\n",
        "    os.path.join(os.getcwd(), 'machine-learning', 'notebook', 'data', 'stud.csv'),\n",
        "]\n",
        "_csv_path = next((p for p in _candidates if os.path.isfile(p)), 'stud.csv')\n",
        "df = pd.read_csv(_csv_path)\n",
        "\n",
        "# Clean column names (remove spaces and special characters)\n",
        "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('/', '_')\n",
        "\n",
        "print(\"Dataset loaded successfully!\")\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(f\"\\nColumn names: {df.columns.tolist()}\")\n",
        "df.head()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load the dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df = \u001b[43mpd\u001b[49m.read_csv(\u001b[33m'\u001b[39m\u001b[33mstud.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Clean column names (remove spaces and special characters)\u001b[39;00m\n\u001b[32m      5\u001b[39m df.columns = df.columns.str.strip().str.lower().str.replace(\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m).str.replace(\u001b[33m'\u001b[39m\u001b[33m/\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
          ]
        }
      ],
      "id": "fac627b8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Display basic info\n",
        "print(\"Dataset Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nMissing Values:\")\n",
        "print(df.isnull().sum())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "",
          "evalue": "",
          "traceback": []
        }
      ],
      "id": "327a37a4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Preparing X and Y variables"
      ],
      "id": "45b9528a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X = df.drop(columns=['math_score'])\n",
        "X.head()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "90d7fe93"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Categories in 'gender' variable:     \", end=\" \")\n",
        "print(df['gender'].unique())\n",
        "\n",
        "print(\"Categories in 'race_ethnicity' variable:  \", end=\" \")\n",
        "print(df['race_ethnicity'].unique())\n",
        "\n",
        "print(\"Categories in 'parental level of education' variable:\", end=\" \")\n",
        "print(df['parental_level_of_education'].unique())\n",
        "\n",
        "print(\"Categories in 'lunch' variable:     \", end=\" \")\n",
        "print(df['lunch'].unique())\n",
        "\n",
        "print(\"Categories in 'test preparation course' variable:     \", end=\" \")\n",
        "print(df['test_preparation_course'].unique())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Categories in 'gender' variable:      "
          ]
        },
        {
          "output_type": "error",
          "ename": "",
          "evalue": "",
          "traceback": []
        }
      ],
      "id": "1fba3c6b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y = df['math_score']\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "ccb9ff6c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create Column Transformer with 3 types of transformers\n",
        "num_features = X.select_dtypes(exclude=[\"object\", \"string\"]).columns\n",
        "cat_features = X.select_dtypes(include=[\"object\", \"string\"]).columns\n",
        "\n",
        "print(f\"Numerical features: {num_features.tolist()}\")\n",
        "print(f\"Categorical features: {cat_features.tolist()}\")\n",
        "\n",
        "numeric_transformer = StandardScaler()\n",
        "# Handle OneHotEncoder compatibility for different sklearn versions\n",
        "try:\n",
        "    # For sklearn >= 1.2\n",
        "    oh_transformer = OneHotEncoder(sparse_output=False)\n",
        "except TypeError:\n",
        "    # For sklearn < 1.2\n",
        "    try:\n",
        "        oh_transformer = OneHotEncoder(sparse=False)\n",
        "    except TypeError:\n",
        "        oh_transformer = OneHotEncoder()\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    [\n",
        "        (\"OneHotEncoder\", oh_transformer, cat_features),\n",
        "        (\"StandardScaler\", numeric_transformer, num_features),        \n",
        "    ]\n",
        ")\n",
        "X = preprocessor.fit_transform(X)\n",
        "\n",
        "# Convert to numpy array if needed (handles sparse matrices)\n",
        "if hasattr(X, 'toarray'):\n",
        "    X = X.toarray()\n",
        "\n",
        "print(f\"\\nTransformed X shape: {X.shape}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "ff275353"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# separate dataset into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "cc7de809"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Create an Evaluate Function to give all metrics after model Training"
      ],
      "id": "cabe4956"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def evaluate_model(true, predicted):\n",
        "    mae = mean_absolute_error(true, predicted)\n",
        "    mse = mean_squared_error(true, predicted)\n",
        "    rmse = np.sqrt(mean_squared_error(true, predicted))\n",
        "    r2_square = r2_score(true, predicted)\n",
        "    return mae, rmse, r2_square"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "b703eff5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "models = {\n",
        "    \"Linear Regression\": LinearRegression(),\n",
        "    \"Lasso\": Lasso(),\n",
        "    \"Ridge\": Ridge(),\n",
        "    \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
        "    \"Decision Tree\": DecisionTreeRegressor(),\n",
        "    \"Random Forest Regressor\": RandomForestRegressor(),\n",
        "    \"XGBRegressor\": XGBRegressor(), \n",
        "    \"CatBoosting Regressor\": CatBoostRegressor(verbose=False),\n",
        "    \"AdaBoost Regressor\": AdaBoostRegressor()\n",
        "}\n",
        "model_list = []\n",
        "r2_list = []\n",
        "\n",
        "for i in range(len(list(models))):\n",
        "    model = list(models.values())[i]\n",
        "    model.fit(X_train, y_train)  # Train model\n",
        "\n",
        "    # Make predictions\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "    \n",
        "    # Evaluate Train and Test dataset\n",
        "    model_train_mae, model_train_rmse, model_train_r2 = evaluate_model(y_train, y_train_pred)\n",
        "    model_test_mae, model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
        "\n",
        "    print(list(models.keys())[i])\n",
        "    model_list.append(list(models.keys())[i])\n",
        "    \n",
        "    print('Model performance for Training set')\n",
        "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
        "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
        "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
        "\n",
        "    print('----------------------------------')\n",
        "    \n",
        "    print('Model performance for Test set')\n",
        "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
        "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
        "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
        "    r2_list.append(model_test_r2)\n",
        "    \n",
        "    print('='*35)\n",
        "    print('\\n')"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "a172afb9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Results"
      ],
      "id": "75ef1cbb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pd.DataFrame(list(zip(model_list, r2_list)), columns=['Model Name', 'R2_Score']).sort_values(by=[\"R2_Score\"], ascending=False)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "e84ac975"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Linear Regression"
      ],
      "id": "422af890"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lin_model = LinearRegression(fit_intercept=True)\n",
        "lin_model = lin_model.fit(X_train, y_train)\n",
        "y_pred = lin_model.predict(X_test)\n",
        "score = r2_score(y_test, y_pred) * 100\n",
        "print(\" Accuracy of the model is %.2f\" % score)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "c88c04d4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot y_pred and y_test"
      ],
      "id": "507271bf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.scatter(y_test, y_pred)\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Predicted')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "0a0f7bc8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.regplot(x=y_test, y=y_pred, ci=None, color='red')\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Predicted')\n",
        "plt.title('Regression Plot: Actual vs Predicted')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "17850fed"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Difference between Actual and Predicted Values"
      ],
      "id": "780d7569"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pred_df = pd.DataFrame({'Actual Value': y_test, 'Predicted Value': y_pred, 'Difference': y_test - y_pred})\n",
        "pred_df"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "",
          "evalue": "",
          "traceback": []
        }
      ],
      "id": "0d1333eb"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}